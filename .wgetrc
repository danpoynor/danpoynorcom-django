###
### Wget initialization file for DanPoynor.com portfolio project
###

## You can use this file to change the default behaviour of wget or to
## avoid having to type many many command-line options. This file does
## not contain a comprehensive list of commands -- look at the manual
## to find out what you can put into this file. You can find this here:
##   $ info wget.info 'Startup File'
## Or online here:
##   https://www.gnu.org/software/wget/manual/wget.html#Startup-File
##
## Wget initialization file can reside in /usr/local/etc/wgetrc
## (global, for all users) or $HOME/.wgetrc (for a single user).
##
## To use the settings in this file, you will have to uncomment them,
## as well as change them, in most cases, as the values on the
## commented-out lines are the default values (e.g. "off").
##
## Command are case-, underscore- and minus-insensitive.
## For example ftp_proxy, ftp-proxy and ftpproxy are the same.


# Read the URLs from string, like ‘-i file’.
#-input urls_for_wget.txt


# Turn mirroring on/off. The same as ‘-m’.
# Turn on options suitable for mirroring. This option turns on recursion and
# time-stamping, sets infinite recursion depth and keeps FTP directory listings.
# It is currently equivalent to ‘-r -N -l inf --no-remove-listing’.
--mirror = on


# Turn on recursive retrieving. See Recursive Download, for more details. The default maximum depth is 5.
#-r
#--recursive


# Turn timestamping on/off. The same as ‘-N’
# If the local file does not exist, or the sizes of the files do not match,
# Wget will download the remote file no matter what the time-stamps say.
#timestamping


# Disallow retrieving outside the directory hierarchy, like ‘--no-parent’.
# Do not ever ascend to the parent directory when retrieving recursively.
# This is a useful option, since it guarantees that only the files below a
# certain hierarchy will be downloaded.
#--no-parent


# If a file is downloaded more than once in the same directory, Wget’s behavior
# depends on a few options, including ‘-nc’. In certain cases, the local file
# will be clobbered, or overwritten, upon repeated download. In other cases
# it will be preserved.
#--no-clobber = on


# Set the maximum number of subdirectories that Wget will recurse into to depth.
# In order to prevent one from accidentally downloading very large websites
# when using recursion this is limited to a depth of 5 by default, i.e., it
# will traverse at most 5 directories deep starting from the provided URL.
# Set ‘-l 0’ or ‘-l inf’ for infinite recursion depth.
#-l depth
#--level=depth

# The --timeout option sets the network timeout. This is the total time that
# wget will wait for a network operation to complete before it gives up.
# This includes the time to establish a connection, send the request, and
# receive a response.
--timeout=30


# Set the read (and write) timeout—the same as ‘--read-timeout=n’.
read_timeout = 30


# Download all ancillary documents necessary for a single HTML page to
# display properly—the same as ‘-p’.
--page-requisites = on


# Add a ‘.html’ extension to ‘text/html’ or ‘application/xhtml+xml’ files that
# lack one, a ‘.css’ extension to ‘text/css’ files that lack one, and a ‘.br’,
# ‘.Z’, ‘.zlib’ or ‘.gz’ to compressed files like ‘-E’. Previously named
# ‘html_extension’ (still acceptable, but deprecated).
--adjust_extension = on


# Convert non-relative links locally. The same as ‘-k’.
--convert-links = on


# Same as ‘-D’
--domains = localhost


# Set directory prefix to prefix. The directory prefix is the directory where
# all other files and subdirectories will be saved to, i.e. the top of the
# retrieval tree. The default is ‘.’ (the current directory).
#-P - docs
